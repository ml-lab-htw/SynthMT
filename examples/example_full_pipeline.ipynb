{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Example: Full Pipeline - From Synthetic Data Tuning to Model Evaluation\n",
    "\n",
    "This notebook demonstrates the complete SynthMT pipeline:\n",
    "1. **Tune synthetic data** to match real microscopy images using embedding-based optimization\n",
    "2. **Generate synthetic samples** with ground-truth masks\n",
    "3. **Tune SAM3Text hyperparameters** on the generated synthetic data\n",
    "4. **Evaluate segmentation and downstream metrics**\n",
    "\n",
    "This end-to-end workflow shows how to create domain-specific synthetic data and use it to optimize a foundation model for microtubule segmentationâ€”without requiring manual annotations.\n",
    "\n",
    "![Full Pipeline Overview](images/data_gen_overview.png)"
   ],
   "id": "8a70676c69579ca4"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "from tqdm import tqdm\n",
    "\n",
    "from examples.utils import create_overlay, sample_to_arrays, get_preprocess_params\n",
    "from synth_mt.config.synthetic_data import SyntheticDataConfig\n",
    "from synth_mt.config.tuning import TuningConfig\n",
    "from synth_mt.data_generation.optimization.embeddings import ImageEmbeddingExtractor\n",
    "from synth_mt.data_generation.optimization.eval import evaluate_synthetic_data_cfg\n",
    "from synth_mt.data_generation.optimization.metrics import precompute_matric_args\n",
    "from synth_mt.data_generation.optimization.objective import objective\n",
    "from synth_mt.benchmark.models.factory import setup_model_factory\n",
    "from synth_mt.benchmark.metrics import calculate_segmentation_metrics, calculate_downstream_metrics\n",
    "from synth_mt.model_hpo.model_hpo import define_search_space, objective_function\n",
    "from synth_mt.utils import preprocessing as pre\n",
    "from synth_mt.utils import postprocessing as post"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Part 1: Tune Synthetic Data to Real Microscopy Images\n",
    "\n",
    "The optimization process aligns synthetic image distributions with real, annotation-free microscopy data:\n",
    "- **Real IRM images** (unlabeled) define the target distribution\n",
    "- **Synthetic images** are generated by the parametric generator $P_\\theta$\n",
    "- Both are embedded using **DINOv2** (pre-trained vision transformer)\n",
    "- Parameters $\\theta$ are iteratively refined to **maximize cosine similarity**"
   ],
   "id": "ef8e1ebeb7bf4b88"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1.1 Load Tuning Configuration\n",
    "\n",
    "The tuning configuration specifies reference images, search space, and optimization settings.\n"
   ],
   "id": "13c1f710c8908e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cfg_path = \"tuning_config_example.json\"\n",
    "tuning_cfg = TuningConfig.load(cfg_path)\n",
    "tuning_cfg.validate()\n",
    "\n",
    "print(f\"Reference images directory: {tuning_cfg.reference_images_dir}\")\n",
    "print(f\"Number of optimization trials: {tuning_cfg.num_trials}\")"
   ],
   "id": "1806eab0778118c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1.2 Compute Reference Embeddings\n",
    "\n",
    "Extract DINOv2 embeddings from real reference images. These define the target distribution.\n"
   ],
   "id": "419b876f61b9b740"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "embedding_extractor = ImageEmbeddingExtractor(tuning_cfg)\n",
    "ref_embeddings = embedding_extractor.extract_from_references()\n",
    "precomputed_kwargs = precompute_matric_args(tuning_cfg, ref_embeddings)\n",
    "\n",
    "print(f\"Extracted embeddings shape: {ref_embeddings.shape}\")"
   ],
   "id": "ec00392f410e2ec2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1.3 Setup and Run Optuna Study\n",
    "\n",
    "We use Optuna with TPE sampler to efficiently search the parameter space."
   ],
   "id": "b4aa3c513070776d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Setup storage\n",
    "db_filename = f\"{tuning_cfg.output_config_id}.db\"\n",
    "db_filepath = os.path.join(tuning_cfg.temp_dir, db_filename)\n",
    "os.makedirs(tuning_cfg.temp_dir, exist_ok=True)\n",
    "storage_uri = f\"sqlite:///{db_filepath}\"\n",
    "\n",
    "# Create study\n",
    "study_synth = optuna.create_study(\n",
    "    sampler=optuna.samplers.TPESampler(),\n",
    "    study_name=tuning_cfg.output_config_id,\n",
    "    storage=storage_uri,\n",
    "    direction=tuning_cfg.direction,\n",
    "    load_if_exists=tuning_cfg.load_if_exists,\n",
    ")\n",
    "\n",
    "# Create objective function with pre-computed arguments\n",
    "objective_fcn = partial(\n",
    "    objective,\n",
    "    tuning_cfg=tuning_cfg,\n",
    "    ref_embeddings=ref_embeddings,\n",
    "    embedding_extractor=embedding_extractor,\n",
    "    **precomputed_kwargs,\n",
    ")"
   ],
   "id": "a1d4a998de2d8c5e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Run optimization (reduce n_trials for demo purposes)\n",
    "N_TRIALS_SYNTH = 10  # Increase for better results\n",
    "study_synth.optimize(objective_fcn, n_trials=N_TRIALS_SYNTH)\n",
    "\n",
    "print(f\"Best trial value: {study_synth.best_value:.4f}\")\n",
    "print(f\"Best parameters: {study_synth.best_params}\")"
   ],
   "id": "6f00690de68caca2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.4 Visualize Optimization Results",
   "id": "281048ff1fd4c1c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = optuna.visualization.matplotlib.plot_optimization_history(study_synth)\n",
    "plt.title(\"Synthetic Data Optimization History\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "b47d19fa0fd3b938",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = optuna.visualization.matplotlib.plot_param_importances(study_synth)\n",
    "plt.title(\"Parameter Importances\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "a5986c1d0f9fdb3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Part 2: Generate Synthetic Samples\n",
    "\n",
    "Using the best configuration from optimization, generate synthetic images with ground-truth masks."
   ],
   "id": "a3f07c0fe33d8d80"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get best configuration\n",
    "best_trial = study_synth.best_trial\n",
    "best_cfg = SyntheticDataConfig.from_trial(best_trial)\n",
    "\n",
    "# Generate 10 samples (single frames)\n",
    "NUM_SYNTHETIC_SAMPLES = 10\n",
    "best_cfg.num_frames = NUM_SYNTHETIC_SAMPLES\n",
    "\n",
    "print(f\"Generating {NUM_SYNTHETIC_SAMPLES} synthetic samples...\")\n",
    "\n",
    "synthetic_frames, synthetic_masks = evaluate_synthetic_data_cfg(\n",
    "    cfg=best_cfg,\n",
    "    tuning_cfg=tuning_cfg,\n",
    "    output_dir=None,\n",
    "    is_for_expert_validation=False,\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(synthetic_frames)} frames\")\n",
    "print(f\"Frame shape: {synthetic_frames[0].shape}\")\n",
    "print(f\"Number of masks per frame: {[len(m) for m in synthetic_masks]}\")"
   ],
   "id": "3840ac6730eb640",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.1 Visualize Generated Samples",
   "id": "fbf9baba083f05f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axs = plt.subplots(2, 5, figsize=(20, 8))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for idx, ax in enumerate(axs):\n",
    "    if idx < len(synthetic_frames):\n",
    "        overlay = create_overlay(synthetic_frames[idx], synthetic_masks[idx])\n",
    "        ax.imshow(overlay)\n",
    "        ax.set_title(f\"Sample {idx+1} ({len(synthetic_masks[idx])} MTs)\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"Generated Synthetic Samples with Instance Masks\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "21962807800bc00d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Part 3: Tune SAM3Text Hyperparameters\n",
    "\n",
    "Now we use the synthetic data to optimize SAM3Text hyperparameters. This enables few-shot adaptation of the foundation model to our specific domain.\n"
   ],
   "id": "8f6c42cca0c36d05"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.1 Prepare Synthetic Dataset for HPO",
   "id": "71ecffd5108fc01c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert synthetic data to the format expected by the HPO objective function\n",
    "class SyntheticDataset:\n",
    "    \"\"\"Simple wrapper to make synthetic data compatible with HPO.\"\"\"\n",
    "\n",
    "    def __init__(self, frames, masks):\n",
    "        self.frames = frames\n",
    "        self.masks = masks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return (image, gt_mask_stack, metadata)\n",
    "        frame = self.frames[idx]\n",
    "        mask_stack = np.stack([np.array(m) for m in self.masks[idx]], axis=0)\n",
    "        return frame, mask_stack, {}\n",
    "\n",
    "    def get_image_path(self, idx):\n",
    "        return f\"synthetic_sample_{idx}\"\n",
    "\n",
    "synthetic_dataset = SyntheticDataset(synthetic_frames, synthetic_masks)\n",
    "print(f\"Synthetic dataset size: {len(synthetic_dataset)}\")"
   ],
   "id": "e0b7ccc7be2b9a0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.2 Setup Model Factory and HPO Study",
   "id": "9727192e99c55381"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "factory = setup_model_factory()\n",
    "\n",
    "MODEL_NAME = \"sam3text\"\n",
    "METRIC = \"IoU\"\n",
    "USE_SKELETON = True\n",
    "N_TRIALS_HPO = 20  # Increase for better results\n",
    "\n",
    "# HPO direction\n",
    "direction = \"maximize\" if METRIC == \"IoU\" else \"minimize\"\n",
    "\n",
    "# Get postprocessing ranges from synthetic data\n",
    "min_area, max_area, min_length, max_length = post.get_area_length_ranges(synthetic_dataset)\n",
    "postprocessing_props = {\n",
    "    \"min_area\": min_area,\n",
    "    \"max_area\": max_area,\n",
    "    \"min_length\": min_length,\n",
    "    \"max_length\": max_length,\n",
    "}\n",
    "\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Metric: {METRIC}\")\n",
    "print(f\"Postprocessing ranges: area=[{min_area}, {max_area}], length=[{min_length}, {max_length}]\")\n"
   ],
   "id": "fc7de9984b3740fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Setup Optuna study for model HPO\n",
    "hpo_db_path = os.path.join(tuning_cfg.temp_dir, f\"hpo_{MODEL_NAME}.db\")\n",
    "hpo_storage_uri = f\"sqlite:///{hpo_db_path}\"\n",
    "\n",
    "study_hpo = optuna.create_study(\n",
    "    study_name=f\"{MODEL_NAME}_hpo\",\n",
    "    storage=hpo_storage_uri,\n",
    "    direction=direction,\n",
    "    load_if_exists=True,\n",
    ")"
   ],
   "id": "8d806faf78e1e97c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.3 Run Hyperparameter Optimization",
   "id": "d6ef599016282569"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "TEMP_DIR = tuning_cfg.temp_dir\n",
    "MODEL_DIR = os.path.join(tuning_cfg.temp_dir, \"models\")\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "study_hpo.optimize(\n",
    "    lambda trial: objective_function(\n",
    "        trial,\n",
    "        factory,\n",
    "        MODEL_NAME,\n",
    "        synthetic_dataset,\n",
    "        postprocessing_props,\n",
    "        METRIC,\n",
    "        TEMP_DIR,\n",
    "        MODEL_DIR,\n",
    "        USE_SKELETON,\n",
    "    ),\n",
    "    n_trials=N_TRIALS_HPO,\n",
    ")\n",
    "\n",
    "print(f\"\\nBest {METRIC}: {study_hpo.best_value:.4f}\")\n",
    "print(f\"Best parameters:\")\n",
    "for key, value in study_hpo.best_params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ],
   "id": "7dee7b59152cae4d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.4 Visualize HPO Results",
   "id": "17b7eec44ba9e363"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = optuna.visualization.matplotlib.plot_optimization_history(study_hpo)\n",
    "plt.title(f\"SAM3Text HPO - {METRIC} Optimization History\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "710e11fbe736a7c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = optuna.visualization.matplotlib.plot_param_importances(study_hpo)\n",
    "plt.title(\"SAM3Text Hyperparameter Importances\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "38811f607c0a4fd0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Part 4: Evaluate the Optimized Model\n",
    "\n",
    "Now we evaluate the optimized SAM3Text model on the synthetic data using both segmentation and downstream metrics.\n"
   ],
   "id": "af8f6e3f37254af2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4.1 Create Model with Best Parameters",
   "id": "4f313ac763a2954c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create model with optimized parameters\n",
    "best_params = study_hpo.best_params.copy()\n",
    "best_params[\"save_dir\"] = MODEL_DIR\n",
    "best_params[\"work_dir\"] = TEMP_DIR\n",
    "\n",
    "optimized_model = factory.create_model(MODEL_NAME, **best_params)\n",
    "optimized_model.load_model()\n",
    "\n",
    "print(f\"Loaded optimized {MODEL_NAME} model\")"
   ],
   "id": "f9b62057bb9b4eb7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4.2 Run Predictions",
   "id": "548712c2de78507b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "preprocess_params = get_preprocess_params(optimized_model)\n",
    "\n",
    "all_gt_masks = []\n",
    "all_pred_masks = []\n",
    "all_images = []\n",
    "\n",
    "for idx in tqdm(range(len(synthetic_dataset)), desc=f\"Running {MODEL_NAME}\"):\n",
    "    image, gt_masks, _ = synthetic_dataset[idx]\n",
    "\n",
    "    processed_image = pre.process_image(image, **preprocess_params)\n",
    "    pred_mask = optimized_model.predict(processed_image)\n",
    "\n",
    "    if pred_mask is None:\n",
    "        print(f\"Warning: Model returned None for sample {idx}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    all_images.append(image)\n",
    "    all_gt_masks.append(gt_masks)\n",
    "    all_pred_masks.append(pred_mask)\n",
    "\n",
    "print(f\"Completed predictions on {len(all_images)} images.\")"
   ],
   "id": "3f79b9ab1468c098",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4.3 Visualize Predictions",
   "id": "5a865332f9dc3976"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_samples = min(5, len(all_images))\n",
    "fig, axs = plt.subplots(n_samples, 3, figsize=(15, 5 * n_samples))\n",
    "\n",
    "for sample_idx in range(n_samples):\n",
    "    gt_overlay = create_overlay(all_images[sample_idx], all_gt_masks[sample_idx])\n",
    "    pred_overlay = create_overlay(all_images[sample_idx], all_pred_masks[sample_idx])\n",
    "\n",
    "    axs[sample_idx, 0].imshow(all_images[sample_idx])\n",
    "    axs[sample_idx, 0].set_title(f\"Sample {sample_idx}: Original\")\n",
    "\n",
    "    axs[sample_idx, 1].imshow(gt_overlay)\n",
    "    axs[sample_idx, 1].set_title(f\"Ground Truth ({all_gt_masks[sample_idx].shape[0]} instances)\")\n",
    "\n",
    "    axs[sample_idx, 2].imshow(pred_overlay)\n",
    "    axs[sample_idx, 2].set_title(f\"Prediction ({len(np.unique(all_pred_masks[sample_idx])) - 1} instances)\")\n",
    "\n",
    "    for ax in axs[sample_idx]:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "plt.suptitle(f\"Optimized {MODEL_NAME} Predictions vs Ground Truth\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "610bae7322980bcd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4.4 Calculate Segmentation Metrics\n",
    "\n",
    "Compute instance segmentation metrics including:\n",
    "- **Precision, Recall, F1** at various IoU thresholds\n",
    "- **Skeletonized IoU (SkIoU)** - IoU computed on skeletonized masks, better suited for filamentous structures\n",
    "- **Average Precision (AP)** across IoU thresholds\n"
   ],
   "id": "78bdd8255bb46b60"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mean_metrics, std_metrics = calculate_segmentation_metrics(\n",
    "    gt_masks=all_gt_masks,\n",
    "    pred_masks=all_pred_masks,\n",
    "    use_skeletonized_version=True,\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Segmentation Metrics for Optimized {MODEL_NAME}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"{'Metric':<30} {'Mean':>12} {'Std':>12}\")\n",
    "print(f\"{'-'*60}\")\n",
    "for key in sorted(mean_metrics.keys()):\n",
    "    std_val = std_metrics.get(key, 0.0)\n",
    "    print(f\"{key:<30} {mean_metrics[key]:>12.4f} {std_val:>12.4f}\")"
   ],
   "id": "957c6839f62fe1b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4.5 Calculate Downstream Metrics\n",
    "\n",
    "Compute biologically relevant downstream metrics:\n",
    "- **Count Error** - Difference in number of detected microtubules\n",
    "- **Length Distribution** - KL divergence between predicted and ground truth length distributions\n",
    "- **Curvature Distribution** - KL divergence between predicted and ground truth curvature distributions\n"
   ],
   "id": "b93d21de571b9663"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "downstream_metrics = calculate_downstream_metrics(\n",
    "    gt_masks=all_gt_masks,\n",
    "    pred_masks=all_pred_masks,\n",
    "    pixel_per_micrometer=9.0,\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Downstream Metrics for Optimized {MODEL_NAME}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"{'Metric':<40} {'Value':>15}\")\n",
    "print(f\"{'-'*60}\")\n",
    "for key, value in downstream_metrics.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key:<40} {value:>15.4f}\")\n",
    "    else:\n",
    "        print(f\"{key:<40} {str(value):>15}\")"
   ],
   "id": "7b8b2c8e9e871f98",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "This notebook demonstrated the complete SynthMT pipeline:\n",
    "\n",
    "1. **Synthetic Data Tuning**: Optimized generation parameters $\\theta$ to match real IRM images using DINOv2 embeddings\n",
    "2. **Sample Generation**: Created 10 synthetic samples with ground-truth instance masks\n",
    "3. **Model HPO**: Tuned SAM3Text hyperparameters using only synthetic data\n",
    "4. **Evaluation**: Computed segmentation (IoU, SkIoU, AP) and downstream metrics (count, length, curvature)\n",
    "\n",
    "Key takeaway: By tuning synthetic data to match real microscopy images, we can effectively adapt foundation models like SAM3Text to the microtubule segmentation domain without requiring manual annotations on real data.\n"
   ],
   "id": "f366a16b4044a913"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save best parameters for future use\n",
    "import json\n",
    "\n",
    "output_config = {\n",
    "    \"synthetic_data_params\": study_synth.best_params,\n",
    "    \"model_hpo_params\": study_hpo.best_params,\n",
    "    \"best_synth_score\": study_synth.best_value,\n",
    "    \"best_model_score\": study_hpo.best_value,\n",
    "}\n",
    "\n",
    "output_path = os.path.join(tuning_cfg.temp_dir, \"full_pipeline_results.json\")\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(output_config, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to: {output_path}\")"
   ],
   "id": "eb237a59d97cad3f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
